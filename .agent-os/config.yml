# Agent OS Configuration v5.7.0
# Clean configuration with sane defaults for compound engineering integration
#
# TOKEN EFFICIENCY NOTE:
# - This file is loaded once per session (not repeatedly)
# - Agents access specific sections via key lookup, not full-file parsing
# - Unused sections do not consume additional context tokens
# v5.7.0: Implementation Guardrails & Codebase Sweep - Verify Target, Reference Audit, /sweep command
# v5.4.1: Task Coverage Validation - Ensures tasks fully cover spec requirements
# v5.4.0: Semantic Coverage Validation - Workflow, data flow, and integration coverage checks
# v5.3.0: Mandatory Session Ledger - Session ledger required when remaining work exists
# v5.2.0: Unified Session Ledger - Multi-session persistence, /orchestrate command
# v5.1.0: UI Testing Integration - E2E tests block implementation, browser validation gates
# v5.0.0: Pattern Consistency - Auto-detect and enforce codebase patterns
# v4.9.0: Autonomous Execution - Supervisor/PM pattern, automatic handoffs, context-aware respawn
# v4.8.2: E2E Stability Patterns - Isolation failures, unique fixtures, semantic waits, parallelism config
# v4.8.0: E2E Testing Methodology Overhaul - Tiered organization, root cause analysis, progressive repair
# v4.6.0: File consolidation - Single execute-tasks.md, removed redundant protocols
# v4.5.0: Test Integrity Maintenance - Proactive existing test analysis and update tasks
# v4.4.0: Quality Enforcement - Blocking gates, context verification, skill invocation checks
# v4.3.0: Codebase Cleanup - Removed legacy/deprecated code, streamlined instructions
# v4.2.0: Testing Alignment - Canonical standards, verification gates, clear ownership, failure classification
# v4.1.0: Unified Execution Protocol - Beads-first orchestration with parallel specialist delegation
# v4.0.1: Direct test execution (not subagent) for real-time output visibility
# v4.0.0: Test Failure Handling Protocol - Orchestrated test execution with subagent delegation
# v3.3.0: Test Execution Monitoring - Real-time streaming, hung test detection, test/code alignment

agent_os_version: 5.7.0

# ================================================
# CONFIGURATION HIERARCHY
# ================================================
# This configuration follows a parent-child toggle pattern:
#
# 1. When a parent section has `enabled: false`, ALL child toggles are
#    ignored regardless of their individual settings.
#
# 2. Child toggles only take effect when their parent is enabled.
#
# 3. Feature dependencies:
#    - TDD enforcement requires quality_hooks.enabled: true
#    - Compound engineering review requires test_infrastructure.enabled: true
#
# See docs/FAQ.md for common configuration questions.

# ================================================
# AGENT EXECUTION MODE
# ================================================
# Choose ONE mode for task execution (mutually exclusive):
# - "multi": Uses Task tool to spawn subagents for parallel work
# - "single": Executes all work in main agent context sequentially
#
# IMPORTANT: Only one mode can be active. Set execution_mode to choose.

execution_mode: "multi" # "multi" | "single"

# Tool configuration per mode (only active mode's tool is used)
multi_agent_tool: claude-code # When execution_mode: "multi"
single_agent_tool: generic # When execution_mode: "single"

# ================================================
# PROJECT CONFIGURATION
# ================================================
project:
  name: "agent-os-setup"
  type: default

# ================================================
# CORE EXECUTION AGENTS
# ================================================
agents:
  claude_code:
    enabled: true
  cursor:
    enabled: false

# ================================================
# TASK FILE STRUCTURE (v2.1+)
# ================================================
task_file_structure:
  enabled: true
  format: "split" # "split" (master + detail files)
  master_file: "tasks.md"
  detail_directory: "tasks/"
  context_optimization: true

# ================================================
# EXECUTION CONFIGURATION
# ================================================
execution:
  orchestrated_mode: true
  parallel_execution: true
  context_optimization: true

  error_handling:
    enabled: true
    automatic_recovery: true
    escalation_threshold: 3
    recovery_timeout: 300

  performance_monitoring:
    enabled: true
    metrics_collection: true
    baseline_comparison: true
    efficiency_tracking: true

# ================================================
# EXECUTION ROLES (Workflow Phase Documentation)
# ================================================
# These define the workflow phases and their instruction files.
# The general-purpose agent loads instructions/agents/{role_name}.md
# when entering each workflow phase.
#
# Active roles (have instruction files):
#   - test_design: Test strategy and design (TDD RED phase)
#   - test_execution: Test running protocol
#   - test_maintenance: Existing test impact analysis
#   - implementation_specialist: Implementation (TDD GREEN phase)
#   - security_sentinel: Security review
#   - pattern_guardian: Pattern discovery and validation
#
# See: docs/GLOSSARY.md for terminology definitions

execution_roles:
  test_design:
    enabled: true
    context_window: 16384
    specialization: "test_design_and_framework_research"

  test_execution:
    enabled: true
    context_window: 6144
    specialization: "test_running_protocol"

  test_maintenance:
    enabled: true
    context_window: 16384
    specialization: "existing_test_analysis"

  implementation_specialist:
    enabled: true
    context_window: 20480
    specialization: "core_feature_implementation"

  security_sentinel:
    enabled: true
    context_window: 16384
    specialization: [security, vulnerability-scanning, owasp]

  pattern_guardian:
    enabled: true
    context_window: 16384
    specialization: "pattern_discovery_and_validation"

# ================================================
# SECURITY SCANNING
# ================================================
security:
  enabled: true
  block_on_p1: true # P1 (CRITICAL) findings block task completion
  owasp_top_10: true

# ================================================
# WORKTREE ISOLATION [DEFERRED]
# ================================================
# Status: DEFERRED - Scripts archived to setup/archive/worktrees/
# Rationale: Current orchestration model (subagent coordination via TodoWrite)
# provides sufficient parallelism without filesystem isolation complexity.
# The infrastructure remains available if future use cases require it.
# See: setup/archive/worktrees/ARCHIVED.md
worktrees:
  enabled: false # DEFERRED - not part of active workflow
  base_directory: ".agent-os/worktrees"
  auto_cleanup: true

# ================================================
# QUALITY HOOKS (v2.2+)
# ================================================
# Implementation: hooks/runner.js
# Called by: .claude/hooks/validate-file.js (Claude Code integration)
# Validators: hooks/validators/*.js
quality_hooks:
  enabled: true
  mode: "balanced" # "strict" | "balanced" | "minimal"
  fail_on_error: false
  auto_fix: true

  # Claude Code native integration
  integration: "claude_code_native"
  hook_script: ".claude/hooks/validate-file.js"
  settings_file: ".claude/settings.json"

  # Performance optimizations
  performance:
    parallel_execution: true
    incremental_validation: true
    smart_caching: true
    cache_ttl: 1800 # 30 minutes

  # Validators (see hooks/config.yml for detailed configuration)
  validators:
    - syntax_validator
    - format_validator
    - lint_validator
    - import_validator
    - type_validator
    - type_checking # v4.3.0: TypeScript type checking (tsc --noEmit)
    - security_validator
    - test_generator
    - test_standards # v2.9.0: Test infrastructure validation

# ================================================
# TYPESCRIPT TYPE CHECKING (v4.3.0+)
# ================================================
# Validates TypeScript types using tsc --noEmit
# Fills the gap where syntax_check.js only validates JavaScript syntax
#
# Implementation: hooks/validators/type_checking.js
# Pre-commit hook: setup/install-typescript-precommit.sh
# Task verification: instructions/core/execute-tasks.md (Step 4.2)

typescript_checking:
  enabled: true

  # When to run type checking
  triggers:
    on_file_write: true # Run on every .ts/.tsx file write
    on_task_completion: true # Mandatory check before task completion
    pre_commit: true # Block commits with type errors

  # Execution settings
  execution:
    command: "tsc --noEmit" # TypeScript check command
    timeout: 60000 # 60 second timeout
    cache_ttl: 5000 # 5 second cache per project (avoid running on every file)

  # Error handling
  error_handling:
    block_on_error: true # Block task completion if type errors exist
    show_full_output: true # Show all type errors, not just summary
    group_by_file: true # Group errors by file for readability

  # Pre-commit hook installation
  pre_commit_hook:
    install_script: "~/.agent-os/setup/install-typescript-precommit.sh"
    bypass_flag: "--no-verify" # How to bypass (documented but discouraged)

# ================================================
# PROJECT TYPES
# ================================================
project_types:
  default:
    instructions: ~/.agent-os/instructions
    standards: ~/.agent-os/standards

  # Example: Add custom project types here
  # rails_api:
  #   instructions: ~/.agent-os/project_types/rails_api/instructions
  #   standards: ~/.agent-os/project_types/rails_api/standards

  # nextjs_app:
  #   instructions: ~/.agent-os/project_types/nextjs_app/instructions
  #   standards: ~/.agent-os/project_types/nextjs_app/standards

default_project_type: default

# ================================================
# DELIVERABLE VERIFICATION (v2.5+)
# ================================================
deliverable_verification:
  enabled: true
  strict_mode: true # Block task completion if deliverables missing
  verify_files: true
  verify_tests: true
  verify_acceptance_criteria: true
  verify_integration: true

# ================================================
# TDD ENFORCEMENT (v2.8+, opt-in v5.3.0+)
# ================================================
# TDD enforcement is OPT-IN by default. AI agents don't need the human
# discipline that strict RED-GREEN-REFACTOR provides. Enable when you want
# stricter test-first workflow.
tdd_enforcement:
  enabled: false # Set true to enable TDD enforcement

  # Enforcement level: strict | standard | relaxed
  # - strict: Block implementation without passing tests (production)
  # - standard: Warn but allow implementation (development)
  # - relaxed: Log only, always allow (prototyping)
  enforcement_level: standard

  # Test-first workflow enforcement
  test_first:
    enabled: false # Set true for test-first requirement
    block_implementation: false # Set true for strict enforcement
    require_passing_tests: true
    allow_refactoring: true

  # Minimal implementation principle
  minimal_implementation:
    enabled: false # Set true to enforce simplicity checks
    enforce_simplicity: true
    check_complexity: true
    max_lines_per_function: 50

  # TDD cycle tracking (RED-GREEN-REFACTOR)
  cycle_tracking:
    enabled: false # Set true to track TDD cycles
    state_directory: ".agent-os/tdd-state"
    persist_history: true
    track_metrics: true

  # TDD workflow hooks
  hooks:
    enabled: false # Set true to enable TDD hooks
    pre_implementation: true # Validate tests exist before implementation
    post_test: true # Validate tests pass after changes
    pre_commit: false # Optional: Validate before git commit

  # Coverage targets
  coverage_targets:
    minimum: 85 # Required minimum coverage
    target: 90 # Target coverage goal
    threshold: 80 # Threshold for warnings

# ================================================
# BEADS ISSUE TRACKING (v2.8+)
# ================================================
beads:
  enabled: true

  # Integration mode
  mode: "hybrid" # "hybrid" (markdown + beads) or "beads_only"

  # Automatic initialization
  auto_init: true
  init_on_project_start: true

  # Sync behavior
  auto_sync: true
  sync_on_task_complete: true
  sync_on_session_end: true

  # Task creation
  create_beads_from_tasks_md: true # Auto-create bd issues from tasks.md
  bidirectional_sync: true # Keep tasks.md and beads in sync

  # MCP integration (Claude Code)
  mcp_server_enabled: true
  mcp_preferred: true # Use MCP functions over CLI when available

  # ID strategy
  id_format: "hash" # "hash" (bd-a1b2) or "sequential" (bd-1, bd-2)

  # Dependency mapping
  auto_detect_dependencies: true
  map_task_dependencies_to_beads: true

  # Status mapping (Agent OS → Beads)
  status_mapping:
    pending: "open"
    in_progress: "in_progress"
    completed: "closed"
    blocked: "blocked"

  # Priority mapping (Agent OS phases → Beads priority 0-4)
  priority_mapping:
    phase_1_pre_execution: 1 # Important
    phase_2_backend: 1 # Important
    phase_3_frontend: 1 # Important
    phase_4_integration: 0 # Critical path
    phase_5_validation: 0 # Critical path
    default: 2 # Normal priority

  # Type mapping
  type_mapping:
    test: "task"
    implementation: "task"
    integration: "task"
    validation: "task"
    bug: "bug"
    enhancement: "enhancement"
    default: "task"

  # Worktree integration
  worktree_compatibility: true
  no_daemon_in_worktrees: true # Prevents branch contamination

  # Discovered work tracking
  track_discovered_work: true
  auto_link_discovered: true # Auto-add "discovered-from" dependencies

  # Stale task detection
  stale_detection:
    enabled: true
    threshold_days: 30
    warn_on_stale: true

# ================================================
# TEST INFRASTRUCTURE RELIABILITY (v2.9+)
# ================================================
# Prevents hung tests, CI failures, and test sprawl through
# mandatory pre-flight checks, timeout enforcement, and validation.

test_infrastructure:
  enabled: true

  # Instruction Loading Protocol
  # Ensures subagents read their instruction files before working
  instruction_loading:
    enabled: true
    mandatory: true # Block work if instructions not confirmed
    verify_confirmation: true # Check subagent confirms understanding
    agent_type_validation: true # Validate correct agent for task type

  # Server Pre-Flight Check
  # Verifies required servers are running before E2E/integration tests
  server_preflight:
    enabled: true
    health_check_timeout: 2000 # 2 seconds per server
    block_on_failure: false # Agent starts prod server if down
    auto_start_prod_server: true # Autonomously build and start production server
    server_type: production # Always use prod server (10-50x faster than dev)

  # Watch Mode Prevention
  # Ensures test commands exit cleanly (no indefinite hanging)
  watch_mode_prevention:
    enabled: true
    detect_vitest_watch: true # vitest without --run
    detect_jest_watch: true # jest with --watch
    detect_playwright_ui: true # playwright with --ui
    auto_fix_commands: true # Add --run flags automatically

  # Timeout Enforcement
  # Hard limits on test execution time
  # CANONICAL SOURCE: These are the single source of truth for timeout values.
  # All other documents should reference this section, not duplicate values.
  # Referenced by:
  #   - standards/test-infrastructure.md
  #   - instructions/agents/test-architect.md
  #   - instructions/agents/test-runner.md
  timeout_enforcement:
    enabled: true
    unit_suite_timeout: 120000 # 2 minutes for unit tests
    integration_suite_timeout: 300000 # 5 minutes for integration
    e2e_suite_timeout: 600000 # 10 minutes for E2E
    idle_detection_timeout: 60000 # 60 seconds no output = hung
    kill_hung_tests: true # Automatically kill hung tests

  # Test Standards Validator
  # Automatic validation of test files on write
  # Implementation: hooks/validators/test_standards.js
  # Called by: hooks/runner.js via Claude Code file write hooks
  test_standards_validator:
    enabled: true
    check_assertions: true # Test must have real assertions
    check_focused_tests: true # No .only() in committed code
    check_file_location: true # Correct dir for test type
    check_timeout_config: true # E2E must have timeouts
    check_debug_patterns: true # No debug scripts as tests

  # Test Sprawl Prevention
  # Prevents accumulation of debug scripts and orphaned tests
  sprawl_prevention:
    enabled: true
    max_console_statements: 5 # More suggests debug script
    block_debug_file_names: true # *-verification.spec.ts etc.
    debug_script_location: "scripts/debug/"
    archive_location: "tests/_archive/"

  # CI-Safe Test Scripts
  # Required package.json scripts for reliable CI execution
  required_scripts:
    - "test:unit:ci" # Unit tests with clean exit
    - "test:e2e:ci" # E2E tests, no auto-start
    - "test:check-servers" # Server health check

# ================================================
# TEST CONTEXT GATHERING (v3.0+)
# ================================================
# Pre-test research phase that gathers library documentation and patterns
# BEFORE test writing begins. Prevents test failures from incorrect API usage.
#
# Implementation: instructions/agents/test-design.md (Phase 1)
# Utilities: hooks/lib/detect-test-libraries.js, hooks/lib/fetch-test-documentation.js
# Workflow: execute-tasks.md Step 2.0

test_context_gathering:
  enabled: true

  # Gate enforcement
  # If true, test-architect CANNOT proceed without context being gathered
  gate_enforcement:
    enabled: true
    block_test_writing: true # Block test creation without context
    warn_only: false # Set true to warn but allow bypass

  # Library detection
  # Automatically detect testing libraries from project files
  library_detection:
    enabled: true
    scan_package_json: true # JavaScript/TypeScript projects
    scan_pyproject: true # Python projects
    scan_gemfile: true # Ruby projects
    detect_versions: true # Extract version numbers
    detect_config_files: true # Find framework config files

  # Documentation source priority
  # Order in which documentation sources are checked
  # Skills are checked FIRST as they're always available and don't require network
  documentation_sources:
    priority:
      - skills # Priority 1: Claude Code skills (always available)
      - dockfork_mcp # Priority 2: DocFork MCP (if available)
      - context7_mcp # Priority 3: Context7 MCP (if available)
      - websearch # Priority 4: WebSearch (always available)
      - webfetch # Priority 5: Direct URL fetch (always available)

    # Instruction files for pattern lookup (skills removed in v5.3.0)
    instruction_files:
      patterns: "standards/" # Code and testing patterns
      specialists: "instructions/agents/" # Specialist guidance
      test_research: "instructions/agents/test-context-gatherer.md" # Test library research

    # MCP tool names to check for availability
    mcp_tools:
      dockfork:
        - mcp__dockfork__get_documentation
        - mcp__dockfork__search_docs
      context7:
        - mcp__context7__get_library_docs
        - mcp__context7__resolve_library_id

  # Pattern catalog
  # Pre-built patterns for common libraries
  pattern_catalog:
    enabled: true
    directory: "standards/testing/patterns"
    builtin_patterns:
      - vitest
      - jest
      - playwright
      - cypress
      - convex
      - prisma
      - supertest

  # Context caching
  # Cache fetched documentation to speed up repeated runs
  caching:
    enabled: true
    cache_directory: ".agent-os/test-context/cache"
    cache_ttl_hours: 24 # How long to cache documentation
    invalidate_on_version_change: true # Refetch if library version changes

  # Output configuration
  # Where to store gathered context for test-architect
  output:
    context_directory: ".agent-os/test-context"
    context_file_pattern: "{task_id}.json"
    patterns_directory: ".agent-os/test-context/patterns"

  # Required documentation sections
  # What to fetch for each library type
  required_sections:
    test_runners:
      - test-lifecycle-hooks
      - assertions
      - configuration
      - mocking
      - async-testing
      - timeout-configuration
    e2e_frameworks:
      - locators
      - assertions
      - page-objects
      - network-interception
      - waiting-strategies
      - parallel-execution
    mocking_libraries:
      - creating-mocks
      - module-mocking
      - spy-functions
      - mock-implementations
      - clearing-mocks
    backend_testing:
      - test-setup
      - database-mocking
      - api-testing
      - authentication
      - transactions

# ================================================
# SKILLS INTEGRATION (v5.3.0+)
# ================================================
# Agent OS skills provide specialized workflows that Claude can invoke.
#
# Note: agent-os-patterns, agent-os-specialists, and agent-os-test-research
# were removed in v5.3.0. Their content now lives in:
#   - standards/ (patterns)
#   - instructions/agents/ (specialists)
#   - instructions/agents/test-context-gatherer.md (test research)
#
# Skills location: ~/.claude/skills/
# See: https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices

skills_integration:
  enabled: true

  # Available Agent OS skills
  skills:
    e2e-test-repair:
      description: "Systematic E2E test suite repair through failure categorization and strategic fixes"
      references:
        - failure-categories.md
        - fix-patterns.md
        - root-cause-analyzer.md
        - quarantine-management.md
        - test-runner-agent.md
        - fix-agent.md
        - handoff-protocol.md

    e2e-test-organization:
      description: "Tiered test organization, feature groups, and workflow-specific execution"
      references:
        - tier-definitions.md
        - feature-groups.md
        - test-inventory.md
        - workflow-commands.md
        - placement-checklist.md

  # Workflow integration points
  # Where instruction files are loaded during task execution
  # Note: Skills replaced with direct instruction file loading in v5.3.0
  workflow_integration:
    create_tasks:
      step: "1.7"
      instructions:
        - standards/testing-standards.md # For code examples in task generation
    test_context_gathering:
      step: "2.0"
      instructions:
        - instructions/agents/test-design.md # Phase 1: Context research
        - standards/testing-standards.md # For testing patterns (fallback)
    test_design:
      step: "2.1"
      instructions:
        - instructions/agents/test-design.md # For test design guidance
    implementation:
      step: "3.0"
      instructions:
        - standards/ # For code style/patterns
        - instructions/agents/implementation-specialist.md # For implementation guidance
    security_review:
      step: "4.5"
      instructions:
        - instructions/agents/security-sentinel.md # For security review guidance

  # Invocation mode
  # "explicit": Only invoke when workflow specifies
  # "auto": Also allow Claude to invoke based on description matching
  invocation_mode: "explicit"

  # Subagent delegation (v3.2.1+)
  # Ensures mandatory instructions and skills are passed to subagents
  subagent_delegation:
    enabled: true
    template_path: "@.agent-os/instructions/utilities/subagent-delegation-template.md"
    enforcement: "advisory" # "advisory" logs warnings, "strict" blocks without template
    required_sections:
      - instruction_loading # Must read role instruction file
      - skill_invocations # Must invoke phase-appropriate skills
      - pattern_lookup_hierarchy # Must check project patterns first
      - global_requirements # Must include CLAUDE.md context

# ================================================
# TEST EXECUTION MONITORING (v3.3.0+)
# ================================================
# Real-time test monitoring with hung test detection and streaming reporters.
# Provides immediate visibility into test progress and automatic intervention.
#
# Implementation:
#   - hooks/lib/test-monitor.js - Main monitoring utility
#   - scripts/reporters/vitest-streaming.js - Vitest reporter
#   - scripts/reporters/playwright-streaming.ts - Playwright reporter
#
# Workflow: execute-tasks.md Steps 2.1, 2.2, 3.0

test_execution_monitoring:
  enabled: true

  # Streaming reporter configuration
  # Reporters emit structured JSON events for real-time parsing
  streaming:
    enabled: true
    vitest_reporter: "./scripts/reporters/vitest-streaming.js"
    playwright_reporter: "./scripts/reporters/playwright-streaming.ts"
    output_format: "structured_json" # "structured_json" | "tap"
    event_prefix: "[AGENT-OS-TEST]"

  # Per-test timeout enforcement
  # More granular than suite-level timeouts in test_infrastructure
  per_test_timeout:
    enabled: true
    unit_test: 5000 # 5 seconds per unit test
    integration_test: 15000 # 15 seconds per integration test
    e2e_test: 30000 # 30 seconds per E2E test
    e2e_step: 10000 # 10 seconds per E2E step

  # Real-time monitoring intervals
  monitoring:
    enabled: true
    poll_interval: 2000 # Check output every 2 seconds
    idle_threshold: 15000 # Alert after 15 seconds no output
    hung_test_threshold: 30000 # Consider test hung after 30 seconds stuck

  # Intervention actions when issues detected
  intervention:
    on_hung_test: "alert" # "alert" | "kill" | "skip"
    on_idle: "warn" # "warn" | "kill"
    on_timeout: "kill" # "kill" | "alert"
    auto_retry_failed: false # Don't auto-retry (let test framework handle)
    max_hung_detections: 3 # Kill after this many hung alerts

  # Output and logging
  output:
    save_events: true
    events_directory: ".agent-os/test-events"
    events_file_pattern: "{task_id}-{timestamp}.json"
    verbose: false # Extra logging for debugging

# ================================================
# TEST/CODE ALIGNMENT (v3.3.0+)
# ================================================
# Ensures tests and implementation code remain aligned throughout TDD cycle.
# Prevents common misalignment issues where tests pass but code is wrong.
#
# Implementation:
#   - instructions/utilities/test-code-alignment-checklist.md
#   - Pattern documentation created by test-architect
#   - Context handoff read by implementation-specialist
#
# Workflow: execute-tasks.md Steps 2.1, 2.2, 2.2a

test_code_alignment:
  enabled: true

  # Pattern documentation (RED phase output)
  pattern_documentation:
    enabled: true
    required: true # Block GREEN phase without pattern docs
    file_pattern: ".agent-os/test-context/{task_id}-patterns-used.json"
    required_sections:
      - test_runner # Framework and version
      - patterns_used # Mocking, assertions, async handling
      - server_requirements # For E2E tests
      - critical_notes # Implementation guidance

  # Context handoff (GREEN phase input)
  context_handoff:
    enabled: true
    required: true # Block implementation without reading patterns
    verify_read: true # Require confirmation of reading pattern file
    checklist_path: "@.agent-os/instructions/utilities/test-code-alignment-checklist.md"

  # Alignment validation (GREEN phase exit)
  alignment_validation:
    enabled: true
    coverage_threshold: 85 # Minimum coverage to verify real testing
    bypass_scan: true # Scan for test-bypass patterns
    block_on_failure: true # Block task completion if alignment fails

    # Patterns to flag (advisory, not blocking)
    bypass_patterns:
      - "process.env.TEST"
      - "process.env.NODE_ENV === 'test'"
      - "if (typeof jest !== 'undefined')"
      - "if (typeof vi !== 'undefined')"

  # Reporting
  output:
    save_results: true
    results_directory: ".agent-os/tdd-state"
    results_file_pattern: "{task_id}-alignment.yml"

# ================================================
# UNIFIED EXECUTION PROTOCOL (v4.1+)
# ================================================
# Combines Context-Aware Execution + Orchestrated Parallel Execution
# Core Principle: Beads-first task creation, then parallel specialist delegation
#
# Implementation: instructions/core/execute-tasks.md
# Command: commands/execute-tasks.md

unified_execution:
  enabled: true

  # Beads-first approach
  beads_first: true
  create_all_tasks_upfront: true # Create ALL beads tasks before any execution
  define_all_dependencies: true # Define ALL dependencies before execution

  # Context management
  context_limit: 0.75 # Stop at 75% context capacity
  checkpoint_interval: 10 # Save progress every N tool calls

  # Parallel execution
  parallel_waves: true # Execute independent tasks in parallel waves
  max_concurrent_subagents: 5 # Maximum parallel subagents per wave

  # User interaction
  auto_continuation: false # Require user approval for continuations
  prompt_on_blocked: true # Always prompt user for blocked tasks
  confirm_execution_plan: true # Show and confirm plan before execution

  # Document synchronization
  sync_documents:
    enabled: true
    update_tasks_md: true # Update tasks.md status as work progresses
    update_task_details: true # Update tasks/task-*.md files
    update_specs: true # Update spec documents if needed
    commit_after_wave: true # Git commit after each wave

  # Checkpointing
  checkpointing:
    enabled: true
    beads_sync_on_checkpoint: true # bd sync at every checkpoint
    git_commit_on_checkpoint: true # Git commit at every checkpoint
    save_orchestrator_state: true # Save full orchestration state

# ================================================
# TEST FAILURE HANDLING PROTOCOL (v4.0.1+)
# ================================================
# Direct test execution with automated failure analysis and delegated fixes.
# Main agent runs tests DIRECTLY for real-time output visibility.
# Only FIXES are delegated to subagents.
#
# Implementation:
#   - .claude/commands/run-tests.md - Full protocol (v4.1)
#   - instructions/agents/test-runner.md - Test execution reference (v3.1)
#
# Workflow:
#   1. Run tests DIRECTLY (user sees real-time streaming output)
#   2. Analyze failures (classify, group by root cause)
#   3. Triage decision (ask user: investigate|fix|skip|rerun)
#   4. Delegate fixes → FIX SUBAGENT(s)
#   5. Run verification tests DIRECTLY
#   6. Loop until resolved
#
# Why direct execution?
#   Subagents don't stream intermediate output - users would see nothing for 5+ minutes.

test_failure_handling:
  enabled: true

  # Execution model (v4.0.1+)
  execution_model:
    main_agent_runs_tests: true # Main agent runs tests directly for real-time output
    main_agent_fixes_code: false # Fixes delegated to subagents
    parallel_fixes: false # Sequential by default (safer), set true for parallel

  # Failure classification types
  classification:
    types:
      - assertion # Expected vs actual mismatch
      - timeout # Test exceeded time limit
      - environment # Missing server, env var, dependency
      - syntax # Parse/compile error
      - runtime # Uncaught exception

  # Triage options presented to user
  triage:
    enabled: true
    options:
      - investigate # Show detailed analysis
      - fix # Spawn fix subagents
      - skip # Continue without fixing
      - rerun # Run failed tests again (flaky)
    auto_triage: false # Always ask user (set true to auto-fix)

  # Fix subagent configuration
  fix_subagent:
    max_iterations: 3 # Max fix attempts before escalating
    verify_after_fix: true # Always run verification after fix
    revert_on_regression: true # Revert if new failures introduced
    report_other_issues: true # Report unrelated issues discovered

  # Analysis persistence
  persistence:
    enabled: true
    directory: ".agent-os/test-failures"
    file_pattern: "{run_id}.json"
    track_fix_history: true # Track what was tried across iterations
    enable_resume: true # Allow resuming fix work after session break

  # Subagent delegation requirements
  subagent_requirements:
    test_runner:
      instruction_file: "instructions/agents/test-runner.md"
      must_use_streaming_reporter: true
      must_use_test_monitor: true
      must_report_protocol_compliance: true
    fix_agent:
      must_read_test_file: true
      must_read_implementation: true
      must_confirm_analysis: true
      must_not_run_tests: true
      must_not_fix_unrelated: true

# ================================================
# TEST INTEGRITY MAINTENANCE (v4.5.0+)
# ================================================
# Proactive analysis of existing tests before implementation begins.
# Identifies tests that will be affected by planned changes and creates
# Beads tasks to update them, preventing test rot and stale tests.
#
# The Problem:
#   Tests become outdated when implementation changes but tests aren't updated.
#   This leads to tests that "pass" but test the wrong behavior.
#
# The Solution:
#   BEFORE building, analyze what existing tests touch the affected code.
#   Create explicit tasks to update those tests alongside implementation.
#
# Implementation:
#   - instructions/agents/test-integrity-analyzer.md
#   - Phase 1.5 in execute-tasks.md
#
# Workflow:
#   1. Phase 1: Create implementation Beads tasks
#   2. Phase 1.5: Analyze existing tests, create update tasks (NEW)
#   3. Phase 2: Execute implementation + test updates together
#   4. Phase 3: Verify all tests pass

test_integrity_maintenance:
  enabled: true

  # When to run test integrity analysis
  triggers:
    before_every_task: true # Run for all tasks (recommended)
    on_file_modification: true # Trigger when modifying existing files
    on_api_changes: true # Extra attention when APIs change
    on_schema_changes: true # Database/type schema changes
    skip_for_new_features: false # Even new features may affect existing tests

  # Test discovery strategies
  discovery:
    # Search for tests that directly test modified files
    search_direct_tests: true
    patterns:
      direct:
        ["**/{filename}.test.{ts,tsx,js}", "**/{filename}.spec.{ts,tsx,js}"]
      co_located: ["**/__tests__/{filename}.{ts,tsx,js}"]

    # Search for tests that mock modified modules
    search_mock_references: true
    mock_patterns:
      vitest: ["vi.mock\\(['\"].*{module}"]
      jest: ["jest.mock\\(['\"].*{module}"]

    # Search for tests that use related fixtures
    search_fixture_references: true
    fixture_locations: ["fixtures/", "__fixtures__/", "test-data/"]

    # Search for E2E tests on affected routes
    search_e2e_routes: true
    e2e_directories: ["tests/e2e/", "e2e/", "playwright/"]

    # Trace import dependencies to find indirect consumers
    trace_import_dependencies: true
    max_dependency_depth: 3 # Limit recursion depth

  # Impact analysis configuration
  analysis:
    # Detect breaking changes that REQUIRE test updates
    detect_breaking_changes: true
    breaking_change_types:
      - function_signature_change
      - return_type_change
      - api_contract_change
      - component_props_change
      - side_effect_change

    # Risk categorization
    categories:
      directly_affected:
        priority: critical
        action: must_update
      mock_dependent:
        priority: high
        action: check_signatures
      fixture_dependent:
        priority: medium
        action: verify_schema
      indirect_consumers:
        priority: medium
        action: verify_behavior
      e2e_affected:
        priority: high
        action: full_verification

  # Automatic Beads task creation
  task_creation:
    auto_create_beads_tasks: true # Create tasks for test updates
    group_related_tests: true # Combine related tests into one task
    max_tests_per_task: 5 # Split if too many tests affected

    # Dependency configuration
    add_dependencies: true # Test updates depend on implementation
    dependency_direction: "test_after_impl" # Implementation first, then update tests

    # Task naming
    task_title_template: "Update tests: {description}"
    task_type: "task"

  # Enforcement modes
  enforcement:
    # Advisory: Log findings, create tasks, but don't block
    # Warning: Show warnings, require acknowledgment
    # Blocking: Cannot proceed without addressing critical tests
    mode: "advisory" # "advisory" | "warning" | "blocking"

    # Block if critical-priority tests are affected and unaddressed
    block_on_critical_tests: false

    # Require explicit test update plan before implementation
    require_test_update_plan: false

    # In blocking mode, these test counts trigger blocks
    blocking_thresholds:
      critical_tests: 1 # Block if ANY critical tests unaddressed
      high_priority_tests: 5 # Block if 5+ high-priority unaddressed
      total_tests: 20 # Block if 20+ total tests unaddressed

  # Output and reporting
  output:
    save_report: true
    report_directory: ".agent-os/test-integrity"
    report_file_pattern: "{task_id}-analysis.json"

    # Include summary in task execution output
    include_in_task_summary: true

    # Generate markdown summary for PR descriptions
    generate_pr_summary: true

  # Integration with other features
  integration:
    # Use test-context-gatherer for pattern detection
    leverage_test_context: true

    # Update test-code-alignment files when tests are updated
    update_alignment_docs: true

    # Include in compound engineering review
    include_in_security_review: false # Security usually doesn't need test updates
    include_in_quality_review: true

  # Scope limits to prevent analysis paralysis
  limits:
    max_tests_to_analyze: 100 # Stop if too many tests affected
    max_files_to_trace: 50 # Limit dependency tracing
    analysis_timeout_seconds: 120 # Hard timeout for analysis phase

    # If limits exceeded, suggest scope reduction
    on_limit_exceeded: "warn_and_continue" # "warn_and_continue" | "stop_and_ask"

# ================================================
# QUALITY LENSES (v5.2+)
# ================================================
# Unified configuration for all quality lenses (Inversion, Pre-Mortem, Evolution).
# By default, lenses are OPT-IN for simple specs to reduce cognitive load.
#
# Reference: instructions/utilities/quality-lenses.md
# Workflow: Steps 2.6, 2.7, 9.7 in create-spec
#
# The key insight: Quality lenses add significant value for complex features
# but create unnecessary overhead for simple changes. This configuration
# makes it easy to apply lenses where they matter most.

quality_lenses:
  enabled: true

  # Opt-in threshold: specs below this estimated work are opt-in by default
  # User can still request lenses for simple specs via --with-lenses flag
  opt_in_threshold_hours: 4 # <4h estimated work = opt-in

  # Which lenses are opt-in vs always-on
  # "always": Applied regardless of complexity
  # "opt-in": Only applied if work > threshold OR explicitly requested
  # "disabled": Never applied
  default_behavior:
    inversion: "opt-in" # Failure mode analysis
    pre_mortem: "opt-in" # Risk projection
    evolution: "opt-in" # Timelessness scoring

  # Override by priority (takes precedence over threshold)
  # P0-P1: Always apply all lenses (critical features need thorough analysis)
  # P2: Apply if > threshold OR has risk factors
  # P3-P4: Opt-in only (simple changes)
  priority_overrides:
    P0: "always"
    P1: "always"
    P2: "threshold" # Use opt_in_threshold_hours
    P3: "opt-in"
    P4: "opt-in"

  # Risk factors that trigger lenses even for simple specs
  # If ANY of these apply, lenses are recommended regardless of threshold
  risk_factors:
    - security_implications # Auth, permissions, secrets
    - data_integrity # Database changes, migrations
    - external_integrations # Third-party APIs, webhooks
    - user_facing_changes # UI that affects many users
    - breaking_changes # API changes, deprecations

  # Skip conditions (ALL must be true to skip for P3-P4)
  skip_conditions:
    - no_security_implications
    - no_data_integrity_risks
    - no_external_integrations
    - estimated_under_threshold
    - pure_docs_or_config

# ================================================
# SEMANTIC COVERAGE VALIDATION (v5.4.0+)
# ================================================
# Validates that specifications address all aspects of user workflows,
# data flows, and integration impacts - not just structural completeness.
#
# Key Insight: A spec can be structurally complete (all files exist, all
# sections filled) yet miss critical workflow aspects like error states,
# data validation paths, or integration impacts.
#
# Reference:
#   - instructions/utilities/post-spec-coverage-checklist.md
#   - instructions/utilities/data-flow-tracing.md
#   - instructions/utilities/integration-impact-analysis.md
# Workflow: Step 2.8 in validate-quality.md, Step 12.5 in create-spec

semantic_coverage:
  enabled: true

  # Score threshold - specs below this are warned/blocked
  min_score: 0.85

  # Enforcement mode
  # "advisory": Log findings, no blocking
  # "warning": Show warnings, require acknowledgment for P2+
  # "blocking": Block on P1 findings
  enforcement_mode: "warning"

  # Which coverage checks to run
  checks:
    # Workflow coverage (UI & user interactions)
    workflow_coverage:
      enabled: true
      weight: 0.40 # 40% of semantic score
      checks:
        - screens_identified
        - navigation_flow
        - empty_states
        - loading_states
        - error_states
        - feedback_mechanisms

    # Data flow coverage (entity lifecycle tracing)
    data_flow_coverage:
      enabled: true
      weight: 0.35 # 35% of semantic score
      checks:
        - create_flow_complete
        - read_flow_complete
        - update_flow_complete
        - delete_flow_complete
        - validation_layers

    # Integration coverage (impact on existing system)
    integration_coverage:
      enabled: true
      weight: 0.25 # 25% of semantic score
      checks:
        - touchpoints_identified
        - breaking_changes_documented
        - affected_features_listed
        - regression_plan_created

  # Severity mapping for findings
  severity:
    P1_critical:
      - "Data created but never displayed"
      - "Missing server validation for user input"
      - "Breaking API change without migration"
      - "Missing error handling for critical path"
      - "Security gap in permission checks"
      - "Missing E2E test for user workflow"

    P2_important:
      - "Missing loading state"
      - "Missing empty state"
      - "Missing error state"
      - "No client validation"
      - "Breaking component changes"
      - "Missing data migration strategy"

    P3_nice_to_have:
      - "No undo capability"
      - "Missing optimistic updates"
      - "Documentation gaps"

  # Quick-spec mode: lighter validation
  quick_spec_behavior:
    enabled: true
    skip_data_flow_tracing: true # Skip entity tracing for quick specs
    skip_integration_impact: false # Still check integration
    reduced_checks: true # Only run critical checks

# ================================================
# TASK COVERAGE VALIDATION (v5.4.1+)
# ================================================
# Validates that generated tasks fully cover specification requirements.
# Runs after task generation to catch gaps before execution.
#
# Key Insight: A semantically complete spec may still produce incomplete tasks
# if task generation misses workflow aspects, data operations, or integrations.
#
# Reference: instructions/utilities/task-coverage-validation.md
# Workflow: Step 1.8 in create-tasks.md

task_coverage:
  enabled: true

  # Score threshold - task sets below this are warned/blocked
  min_score: 0.85

  # Enforcement mode
  # "advisory": Log gaps, no blocking
  # "warning": Show warnings, require acknowledgment for P2+
  # "blocking": Block on P1 gaps, auto-generate missing tasks
  enforcement_mode: "warning"

  # Coverage weights for scoring
  weights:
    workflow: 0.30 # Routes, components, states
    data_flow: 0.35 # CRUD operations, validation
    integration: 0.20 # Breaking changes, dependencies
    testing: 0.15 # E2E tests, browser validation

  # What to check in each category
  checks:
    workflow:
      - routes_have_tasks
      - components_have_state_coverage
      - feedback_mechanisms_covered

    data_flow:
      - entities_have_crud_tasks
      - validation_in_acceptance_criteria
      - migration_tasks_if_needed

    integration:
      - breaking_changes_have_tasks
      - external_deps_have_tasks
      - affected_features_addressed

    testing:
      - user_flows_have_e2e_tasks
      - e2e_blocks_implementation
      - browser_validation_tasks

  # Severity for missing coverage
  severity:
    P1_must_add:
      - "Missing route/page task"
      - "Missing entity CRUD task"
      - "Missing E2E test task"
      - "Missing breaking change migration task"
      - "E2E test not blocking implementation"
      - "Missing server validation in AC"

    P2_should_add:
      - "Missing empty state in AC"
      - "Missing loading state in AC"
      - "Missing error state in AC"
      - "Missing browser validation task"
      - "Missing client validation in AC"

# ================================================
# PRE-MORTEM LENS (v5.2+)
# ================================================
# Pre-mortem risk analysis that identifies potential failure causes
# by imagining the feature has already failed and working backward.
#
# Reference: instructions/utilities/quality-lenses.md#pre-mortem-lens
# Template: templates/pre-mortem-analysis.md.template
# Workflow: Step 2.7 in create-spec.md

pre_mortem_lens:
  enabled: true

  # Inherits from quality_lenses.priority_overrides
  # These settings are ADDITIONAL configuration for pre-mortem specific behavior
  mandatory_for: ["P0", "P1"] # Overridden by quality_lenses.priority_overrides

  # Optional for P2-P4 features (apply if: external deps, data risks, security, complexity)
  optional_for: ["P2", "P3", "P4"]

  # Risk scoring configuration
  scoring:
    # Risk score threshold - scores above this require mitigation
    risk_threshold: 12

    # Scoring formula: Likelihood x Impact x (Detectability / 2)
    formula: "L * I * (D / 2)"

    # Likelihood scale (1-5)
    likelihood_scale:
      1: "Rare (<5%)"
      2: "Unlikely (5-20%)"
      3: "Possible (20-50%)"
      4: "Likely (50-80%)"
      5: "Almost Certain (>80%)"

    # Impact scale (1-5)
    impact_scale:
      1: "Minimal (cosmetic)"
      2: "Minor (workaround exists)"
      3: "Moderate (degraded UX)"
      4: "Major (core function broken)"
      5: "Catastrophic (total failure)"

    # Detectability scale (1-5)
    detectability_scale:
      1: "Obvious (immediate)"
      2: "Easy (<1 day)"
      3: "Moderate (1-7 days)"
      4: "Difficult (7-30 days)"
      5: "Hidden (30+ days)"

  # Risk categories to analyze
  categories:
    - technical # Architecture, performance, security, integration
    - product # UX, value proposition, adoption, market fit
    - process # Communication, coordination, timeline, resources
    - external # Dependencies, market changes, regulatory, competition

  # Minimum requirements by priority
  requirements:
    P0_P1:
      min_risks: 8 # At least 2 per category
      min_mitigations: "all_above_threshold"
      early_warnings: 5
      time_budget_min: 15
    P2:
      min_risks: 4 # At least 1 per category
      min_mitigations: "score_above_16"
      early_warnings: 3
      time_budget_min: 10
    P3_P4:
      min_risks: 4
      min_mitigations: "critical_only"
      early_warnings: 0 # Optional
      time_budget_min: 5

  # Output configuration
  output:
    file_location: "sub-specs/pre-mortem-analysis.md"
    link_to_acceptance_criteria: true
    include_early_warnings: true
    include_review_schedule: true

  # Integration with other spec sections
  integration:
    technical_spec: true # Feed technical risks into architecture decisions
    ux_ui_spec: true # Feed product risks into user flow architecture
    implementation_plan: true # Feed process risks into timeline
    integration_requirements: true # Feed external risks into dependencies

# ================================================
# PATTERN CONSISTENCY (v5.0+)
# ================================================
# Ensures new features integrate seamlessly with existing codebase patterns
# by discovering, documenting, and enforcing architectural conventions.
#
# Solves: New code using different patterns than existing code (e.g., slugs vs IDs in URLs)
#
# Implementation:
#   - instructions/agents/pattern-guardian.md - Pattern discovery and validation
#   - templates/patterns/*.md.template - Documentation templates
#   - Step 0.5 in create-spec.md, Step 4.5 in execute-tasks.md
#
# Workflow:
#   1. Pattern Discovery: Analyze codebase before spec creation
#   2. Pattern Documentation: Persist patterns to .agent-os/patterns/
#   3. Pattern Constraints: Include in task definitions
#   4. Pattern Validation: Verify new code matches patterns

pattern_consistency:
  enabled: true

  # Pattern discovery configuration
  # Automatically analyzes codebase to detect existing patterns
  discovery:
    enabled: true
    auto_run: true # Run before spec creation
    refresh_threshold_days: 7 # Re-run if patterns older than this
    confidence_threshold: 0.7 # Minimum confidence to accept a pattern (0.0-1.0)

    # Source directories to scan
    source_directories:
      - src/
      - app/
      - lib/
      - pages/
      - components/
      - api/
      - routes/
      - controllers/
      - models/
      - services/

    # Directories to exclude from scanning
    exclude_directories:
      - node_modules/
      - .git/
      - dist/
      - build/
      - .next/
      - __pycache__/
      - venv/
      - coverage/

    # Minimum samples for pattern detection
    minimum_samples:
      url_structure: 3
      naming_conventions: 10
      component_structure: 5
      state_management: 2
      api_patterns: 3
      authentication: 1
      form_handling: 2
      error_handling: 5
      testing_patterns: 5

  # Pattern documentation configuration
  documentation:
    output_directory: ".agent-os/patterns"
    format: "markdown"
    include_evidence: true # Include file:line references
    max_evidence_per_category: 10 # Limit evidence to prevent bloat

    # Files generated
    structure:
      metadata: "_metadata.yml"
      summary: "architecture.md"
      frontend:
        - routing.md
        - components.md
        - state.md
        - forms.md
      backend:
        - api.md
        - auth.md
      testing:
        - patterns.md
      global:
        - naming.md
        - error-handling.md

  # Pattern categories to detect
  categories:
    url_structure:
      enabled: true
      priority: high # Most common source of integration issues
      description: "URL parameter style (ID vs slug vs UUID)"

    naming_conventions:
      enabled: true
      priority: high
      description: "File and code naming patterns"

    component_structure:
      enabled: true
      priority: medium
      description: "Frontend component organization"

    state_management:
      enabled: true
      priority: medium
      description: "State libraries and patterns"

    api_patterns:
      enabled: true
      priority: high
      description: "API response format and conventions"

    authentication:
      enabled: true
      priority: low
      description: "Auth mechanism and storage"

    form_handling:
      enabled: true
      priority: medium
      description: "Form libraries and validation"

    error_handling:
      enabled: true
      priority: medium
      description: "Error display and reporting patterns"

    testing_patterns:
      enabled: true
      priority: low
      description: "Test framework and structure"

  # Consistency enforcement configuration
  enforcement:
    # Advisory: Log findings but don't block
    # Warning: Show warnings, require acknowledgment
    # Blocking: Cannot proceed without addressing deviations
    mode: "advisory" # "advisory" | "warning" | "blocking"

    # When to check for consistency
    check_on_spec_creation: true # During create-spec
    check_on_task_creation: true # During create-tasks
    check_on_implementation: true # During task execution
    check_before_completion: true # Before marking task complete

    # Deviation handling
    allow_justified_deviations: true # Allow if developer provides reason
    require_justification: true # Must explain why deviating

    # In blocking mode, these trigger blocks
    blocking_triggers:
      any_unjustified_deviation: true
      high_priority_pattern_violation: true
      multiple_deviations: 3 # Block if 3+ deviations in one task

  # Workflow integration
  workflow_integration:
    create_spec:
      step: "0.5"
      action: "Run pattern discovery if patterns stale or missing"

    create_tasks:
      step: "1"
      action: "Load patterns, check spec alignment, add constraints to tasks"

    execute_tasks:
      step: "3.0"
      action: "Load patterns before implementation"

    post_implementation:
      step: "4.5"
      action: "Validate new code against patterns"

  # Deviation documentation
  deviations:
    # Where to document approved deviations
    documentation_location: ".agent-os/patterns/deviations/"

    # Whether to update patterns when deviations are approved
    update_patterns_on_approval: false # Manual pattern updates only (safer)

    # Require architectural decision record for deviations
    require_adr: false # Set true for stricter governance

  # Output and reporting
  output:
    save_report: true
    report_directory: ".agent-os/pattern-analysis"
    report_file_pattern: "{timestamp}-analysis.json"

    # Console output verbosity
    console_output: "summary" # "summary" | "detailed" | "minimal"

    # Include in task summaries
    include_in_task_summary: true

# ================================================
# UI TESTING INTEGRATION (v5.1.0+)
# ================================================
# Ensures UI components and user flows include proper E2E testing,
# accessibility validation, and browser compatibility checks.
#
# Key Features:
#   - E2E tests BLOCK implementation task completion
#   - Browser validation gate before task completion
#   - Accessibility (WCAG 2.1 AA) enforcement
#   - Core Web Vitals measurement
#
# Implementation:
#   - instructions/utilities/ui-component-testing-strategy.md
#   - instructions/utilities/e2e-test-placement-checklist.md
#   - instructions/utilities/ui-acceptance-criteria-checklist.md
#   - standards/e2e-ui-testing-standards.md
#   - execute-tasks.md Step 4.2.5 (Browser Validation Gate)

ui_testing:
  enabled: true

  # E2E Test Strategy Requirements
  # Enforces creation of e2e-test-strategy.md for UI specs
  e2e_strategy:
    enabled: true
    required_for_ui_specs: true # Block task creation without E2E strategy
    require_user_flow_inventory: true # All flows must be documented
    require_tier_assignment: true # smoke/core/regression for each flow
    require_data_testid_specs: true # data-testid for interactive elements
    require_accessibility_matrix: true # Per-page a11y requirements
    require_browser_matrix: true # Browser compatibility requirements

  # E2E Test Blocking Dependencies
  # Makes E2E tests block implementation task completion
  blocking_dependencies:
    enabled: true
    e2e_blocks_implementation: true # test-user-flow blocks impl-user-flow
    browser_validation_required: true # validate-browser task required
    enforcement_mode: "blocking" # "blocking" | "warning" | "advisory"

  # Browser Validation Gate
  # Executed before UI task completion (Step 4.2.5)
  browser_validation_gate:
    enabled: true
    trigger: "before_task_completion" # When to run validation
    browsers:
      chrome: true # Required
      firefox: true # Required
      safari: false # Optional (set true if supporting Safari)
      mobile: true # Required
    block_on_failure: true # Block task if validation fails

  # Accessibility Requirements
  # WCAG 2.1 AA compliance enforcement
  accessibility:
    enabled: true
    wcag_level: "AA" # "A" | "AA" | "AAA"
    axe_core_integration: true
    block_on_critical: true # Block on critical violations
    block_on_serious: false # Warn but don't block on serious
    keyboard_navigation_required: true
    screen_reader_testing: "recommended" # "required" | "recommended" | "optional"

  # Performance Requirements
  # Core Web Vitals targets
  performance:
    enabled: true
    core_web_vitals:
      lcp_target: 2500 # ms - Largest Contentful Paint
      lcp_warning: 4000 # ms
      cls_target: 0.1 # Cumulative Layout Shift
      cls_warning: 0.25
      inp_target: 200 # ms - Interaction to Next Paint
      inp_warning: 500
    block_on_critical_performance: false # Warn but don't block
    measure_before_completion: true

  # Component Testing Strategy
  # Determines test type per component
  component_testing:
    unit_tests:
      required_for: ["presentational", "form_input", "interactive"]
      co_located: true # Component.test.tsx next to Component.tsx
    integration_tests:
      required_for: ["form_container", "data_display"]
      location: "tests/integration/"
    e2e_tests:
      required_for: ["page", "user_flow"]
      location: "tests/e2e/"

  # Acceptance Criteria Requirements
  # What must be checked before task completion
  acceptance_criteria:
    components:
      - "Unit tests pass"
      - "Accessibility scan passes (0 critical violations)"
      - "data-testid attributes present"
    user_flows:
      - "E2E tests pass"
      - "Accessibility scan passes (WCAG 2.1 AA)"
      - "Browser validation completed"
    pages:
      - "E2E tests pass"
      - "Accessibility scan passes"
      - "Core Web Vitals measured"

  # Validation in /validate-quality
  quality_validation:
    check_e2e_strategy: true
    check_ux_ui_spec: true
    check_task_dependencies: true
    check_acceptance_criteria: true
    check_data_testid_coverage: true

# ================================================
# E2E TESTING (v5.2+)
# ================================================
# Unified E2E testing command that consolidates test running, failure analysis,
# and fixing into a single interactive workflow.
#
# Command: /e2e (replaces /run-tests and /test-health)
# Skill: e2e-testing (consolidates e2e-test-repair and e2e-test-organization)
#
# Features:
#   - Production server auto-start (10-50x faster than dev)
#   - Tiered execution (smoke -> core -> regression)
#   - Failure categorization and root cause analysis
#   - Priority-based fixing with sample verification
#   - Context handoff for multi-session workflows
#   - Quarantine management with Beads tracking

e2e:
  enabled: true
  tiers:
    smoke:
      timeout_minutes: 3
      stop_on_failure: true
    core:
      timeout_minutes: 15
      stop_on_failure: false
    regression:
      timeout_minutes: 45
      stop_on_failure: false
  loop:
    max_iterations: 3
    max_total_iterations: 10
    success_threshold: 0.95
    quarantine_after_failures: 3
  fix:
    prioritize_by: "impact"
    verify_sample_size: 3

# ================================================
# E2E TEST ORGANIZATION (legacy config, merged into e2e)
# ================================================
# Tiered test organization for efficient execution across development workflows.
# Enables running the right tests at the right time (smoke for commits, core for PRs, etc.)
#
# Note: This section is kept for backwards compatibility.
# New configurations should use the 'e2e' section above.
#
# Files:
#   - tests/e2e/test-inventory.ts - Source of truth for test categorization
#   - scripts/test-organization/generate-inventory.ts - Inventory generator

e2e_test_organization:
  enabled: true

  # Test tier definitions
  tiers:
    smoke:
      description: "Critical user journeys"
      target_duration: 120 # 2 minutes
      when_to_run: "every_commit"
      examples:
        - registration
        - login
        - dashboard_access

    core:
      description: "Main feature coverage"
      target_duration: 1200 # 20 minutes
      when_to_run: "pull_request"
      examples:
        - feature_happy_paths
        - crud_operations
        - user_workflows

    regression:
      description: "Edge cases and validation"
      target_duration: 2700 # 45 minutes
      when_to_run: "nightly"
      examples:
        - validation_errors
        - edge_cases
        - security_tests

    quarantine:
      description: "Broken or flaky tests"
      when_to_run: "manual_only"
      requires_tracking_issue: true
      max_age_days: 30

  # Feature group configuration
  feature_groups:
    enabled: true
    auto_detect: true # Try to detect from test file paths
    standard_groups:
      - auth
      - dashboard
      - search
      - settings
      - user-management
      - data-import

  # Test inventory configuration
  inventory:
    enabled: true
    file_path: "tests/e2e/test-inventory.ts"
    auto_generate: true
    validate_on_commit: false # Set true to block commits with invalid inventory

  # Tiered execution scripts (added to package.json)
  scripts:
    smoke: "TEST_TIER=smoke playwright test"
    core: "TEST_TIER=core playwright test"
    regression: "TEST_TIER=regression playwright test"
    full: "playwright test"
    list: "npx tsx tests/e2e/test-inventory.ts --list"

  # Integration with fix protocols
  repair_integration:
    smoke_first: true # Always run smoke before full repair
    sample_size: 30 # Tests to sample for root cause analysis
    progressive_expansion: true # Sample -> Core -> Regression -> Full

# ================================================
# AUTONOMOUS EXECUTION (v4.9.0+)
# ================================================
# Supervisor/PM pattern for fully autonomous task execution.
# Survives context limits through automatic PM respawn with Beads state.
#
# Implementation: .claude/commands/context-aware.md
# State: .agent-os/supervisor/pm-handoff.json
#
# Workflow:
#   1. Supervisor spawns PM subagent
#   2. PM executes /execute-tasks protocol autonomously
#   3. PM hands off at 85% context, saves state to Beads
#   4. Supervisor spawns new PM with continuation context
#   5. Repeats until all tasks complete or user aborts

autonomous_execution:
  enabled: true

  # Context limits
  pm_context_limit: 0.85 # PM triggers handoff at 85%
  supervisor_context_limit: 0.95 # Emergency stop (should never hit)

  # Session limits (safety)
  max_pm_sessions: 20 # Maximum PM respawns before requiring user intervention

  # State persistence (unified session ledger)
  handoff_directory: ".agent-os"
  handoff_file: "session-ledger.md"
  ledger_archive_directory: ".agent-os/ledgers"
  session_history: true # Keep log of all PM sessions

  # User interaction
  require_user_confirmation: true # Confirm before starting execution
  auto_resume: true # Session start auto-detects ledger and offers resume
  prompt_on_blocker: true # Always ask user for blocker resolution

  # PM delegation
  pm_subagent_type: "general-purpose"
  pm_follows_execute_tasks: true # PM must use /execute-tasks protocol
  pm_spawns_specialists: true # PM can spawn implementation specialists

  # Quality gates (inherited from execute-tasks)
  verify_deliverables: true
  run_tests_before_handoff: true
  require_clean_commits: true

# ================================================
# EVOLUTION SCORING (v5.2+)
# ================================================
# Evaluates spec and implementation quality through an "evolution lens"
# that focuses on maintainability, extensibility, debuggability, and simplicity.
#
# Reference: instructions/utilities/quality-lenses.md#evolution-scoring
# Integration:
#   - create-spec.md Step 9.7 - Score specs before completion
#   - execute-tasks.md Step 4.2.7 - Check deliverables for anti-patterns
#
# NOTE: Controlled by quality_lenses.priority_overrides for when to apply
#
# Workflow:
#   1. Spec Creation: Score spec quality, block/warn if below threshold
#   2. Task Execution: Verify implementation matches evolution requirements
#   3. Deliverable Check: Flag new anti-patterns introduced during implementation

evolution_scoring:
  enabled: true

  # Score threshold (0-10)
  # Specs/implementations must score at or above this to pass
  threshold: 7

  # Enforcement mode
  # "warning": Show issues, allow override with justification
  # "blocking": Cannot proceed without meeting threshold
  enforcement_mode: "warning"

  # Where to apply evolution scoring
  apply_to:
    specs: true # Evaluate spec quality (Step 9.7)
    tasks: true # Check task deliverables (Step 4.2.7)
    deliverables: false # Reserved for future: detailed file-level analysis

  # Scoring categories (each scored 0-10)
  categories:
    maintainability:
      enabled: true
      weight: 1.0
      criteria:
        - separation_of_concerns
        - modular_design
        - clear_dependencies
        - testing_strategy

    extensibility:
      enabled: true
      weight: 1.0
      criteria:
        - extension_points
        - future_considerations
        - backwards_compatibility
        - api_versioning

    debuggability:
      enabled: true
      weight: 1.0
      criteria:
        - error_handling_patterns
        - logging_strategy
        - observable_boundaries
        - troubleshooting_guidance

    simplicity:
      enabled: true
      weight: 1.0
      criteria:
        - minimal_dependencies
        - clear_data_flow
        - appropriate_abstraction
        - no_over_engineering

  # Anti-pattern detection (for task deliverables)
  anti_patterns:
    global:
      - god_objects # Class/module with >10 responsibilities
      - hidden_dependencies # Dependencies not in function signature
      - magic_values # Unexplained constants or strings
      - nested_callbacks # Callback depth > 3
      - mixed_abstractions # High-level mixed with low-level code
      - excessive_coupling # Module depends on >5 other modules

    # Additional patterns loaded from spec's inversion analysis
    load_from_inversion_analysis: true

  # Override handling
  overrides:
    require_justification: true
    justification_min_length: 50 # Characters
    save_overrides: true
    override_directory: ".agent-os/evolution"

  # Reporting
  output:
    save_reports: true
    report_directory: ".agent-os/evolution"
    spec_report_pattern: "{spec_folder}/evolution-score.json"
    task_report_pattern: "{task_id}-check.json"
    include_in_pr_summary: true

# ================================================
# E2E REPAIR PROTOCOL (v4.9.0+)
# ================================================
# Configuration for /fix-e2e-tests and /fix-e2e-large commands.
# Enables systematic repair using PRODUCTION SERVER execution.
#
# CRITICAL (v4.9.0): E2E tests MUST run against production server.
# Tests run 10-50x faster. No sharding needed.

e2e_repair_protocol:
  enabled: true

  # Production server requirement (v4.9.0 - MANDATORY)
  production_server:
    required: true # MUST use production server
    build_command: "npm run build"
    start_command: "npm run start"
    port: 3000
    health_check_url: "http://localhost:3000"
    startup_timeout: 60 # seconds
    rebuild_after_app_fix: true # MUST rebuild after any app code change

  # Server management
  server_management:
    kill_existing_before_start: true
    server_log_path: ".agent-os/e2e-repair/server.log"
    server_pid_path: ".agent-os/e2e-repair/server.pid"
    keep_running_on_handoff: true # Avoid rebuild time on resume

  # Parallelism (simplified - no sharding needed with prod server)
  parallelism:
    # No sharding needed - prod server handles concurrent requests
    sharding_enabled: false
    workers: 4 # Playwright workers (prod server handles it)

  # Root cause analysis
  root_cause_analysis:
    enabled: true
    group_by_error_signature: true
    estimate_impact: true
    rank_by_impact_to_effort: true

  # Progressive verification
  progressive_verification:
    enabled: true
    sample_first: true
    sample_size: 30
    expansion_threshold: 0.90 # Expand when sample hits 90%

  # Session persistence
  session_persistence:
    enabled: true
    state_directory: ".agent-os/e2e-repair"
    state_file: "session-state.json"
    enable_resume: true
    checkpoint_after_each_fix: true

  # Quarantine management
  quarantine:
    enabled: true
    max_failures_before_quarantine: 3
    require_tracking_issue: true
    weekly_review_reminder: true
    max_quarantine_age_days: 30
    delete_stale_quarantine: false # Set true to auto-delete old quarantined tests

  # Success criteria
  success_criteria:
    target_pass_rate: 0.95 # 95%
    acceptable_pass_rate: 0.90 # 90% after 3 cycles
    escalation_threshold: 0.70 # Escalate if below 70% after 2 cycles

  # Performance expectations (with production server)
  performance:
    # Discovery time (running full suite)
    discovery_100_tests: "30s"
    discovery_250_tests: "1min"
    discovery_500_tests: "2min"
    # Total repair time
    total_100_tests: "5min"
    total_250_tests: "10min"
    total_500_tests: "15min"

# ================================================
# IMPLEMENTATION GUARDRAILS (v5.7.0+)
# ================================================
# Verify Target and Reference Audit protocols for the implementation specialist.
# These prevent the two most common implementation errors:
# 1. Editing the wrong file (wrong component, wrong handler)
# 2. Missing stale references after multi-file changes

implementation_guardrails:
  enabled: true

  # Verify Target: Trace import/render chain before editing files
  verify_target:
    enabled: true
    # enforcement_mode: "advisory" logs a reminder, "warning" shows alert, "blocking" prevents edits
    enforcement_mode: "advisory"
    # Skip verification when user provides explicit file paths
    trust_user_paths: true

  # Reference Audit: Grep all references after multi-file changes
  reference_audit:
    enabled: true
    enforcement_mode: "advisory"
    # Trigger audit when this many files are modified in a single task
    file_threshold: 3
    # Include test files in the audit
    include_tests: true
    # Include barrel files (index.ts) in the audit
    include_barrel_files: true

# ================================================
# CODEBASE SWEEP (v5.7.0+)
# ================================================
# Configuration for the /sweep command.
# Automated codebase maintenance: dead exports, unused deps, type errors, stale refs.

codebase_sweep:
  enabled: true

  # Which categories to check
  categories:
    typescript: true
    dead_exports: true
    unused_deps: true
    stale_refs: true
    code_markers: true
    large_files: true

  # Thresholds
  thresholds:
    large_file_lines: 500

  # Safety: Only auto-fix SAFE findings, report REVIEW findings
  auto_fix: true
  enforcement_mode: "advisory" # advisory | warning
